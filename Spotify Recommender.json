{"id":"fbee32c5-f9b7-45a2-bc21-b256c1c3125c","data":{"nodes":[{"width":384,"height":339,"id":"CustomComponent-RNopE","type":"genericNode","position":{"x":1826.8240461960877,"y":184.90282602049646},"data":{"type":"CustomComponent","node":{"template":{"llm":{"type":"BaseLLM","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"llm","display_name":"llm","advanced":false,"dynamic":false,"info":"","value":""},"prompt":{"type":"PromptTemplate","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"prompt","display_name":"prompt","advanced":false,"dynamic":false,"info":"","value":""},"vector_store":{"type":"VectorStore","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"vector_store","display_name":"vector_store","advanced":false,"dynamic":false,"info":"","value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow import CustomComponent\nfrom langflow.field_typing import Data, BaseLLM, PromptTemplate, VectorStore, Chain\nfrom langchain.chains import RetrievalQA\n\n\nclass Component(CustomComponent):\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n\n    def build(self, llm: BaseLLM, prompt: PromptTemplate, vector_store: VectorStore) -> Chain:\n        retrieval_qa = RetrievalQA.from_llm(llm=llm, prompt=prompt, retriever=vector_store.as_retriever())\n        return retrieval_qa","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":false,"dynamic":true,"info":""},"_type":"CustomComponent"},"base_classes":["Chain"],"display_name":"RetrievalQA","documentation":"http://docs.langflow.org/components/custom","custom_fields":{"llm":null,"prompt":null,"vector_store":null},"output_types":["Chain"],"field_formatters":{},"beta":true},"id":"CustomComponent-RNopE"},"selected":false,"dragging":false,"positionAbsolute":{"x":1826.8240461960877,"y":184.90282602049646}},{"id":"AstraDBSearch-yJfFU","type":"genericNode","position":{"x":-1019.7979236125238,"y":5458.228225992009},"data":{"type":"AstraDBSearch","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"Embedding to use","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input Value","advanced":false,"dynamic":false,"info":"Input value to search","load_from_db":false,"title_case":false,"input_types":["Text"]},"api_endpoint":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"api_endpoint","display_name":"API Endpoint","advanced":false,"dynamic":false,"info":"API endpoint URL for the Astra DB service.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"https://dfa19251-eb15-46c4-8602-1997dd83fe7a-us-east-2.apps.astra.datastax.com"},"batch_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"batch_size","display_name":"Batch Size","advanced":true,"dynamic":false,"info":"Optional number of records to process in a single batch.","load_from_db":false,"title_case":false},"bulk_delete_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_delete_concurrency","display_name":"Bulk Delete Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk delete operations.","load_from_db":false,"title_case":false},"bulk_insert_batch_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_batch_concurrency","display_name":"Bulk Insert Batch Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations.","load_from_db":false,"title_case":false},"bulk_insert_overwrite_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_overwrite_concurrency","display_name":"Bulk Insert Overwrite Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing records.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langflow.components.vectorstores.AstraDB import AstraDBVectorStoreComponent\nfrom langflow.components.vectorstores.base.model import LCVectorStoreComponent\nfrom langflow.field_typing import Embeddings, Text\nfrom langflow.schema import Record\n\n\nclass AstraDBSearchComponent(LCVectorStoreComponent):\n    display_name = \"Astra DB Search\"\n    description = \"Searches an existing Astra DB Vector Store.\"\n    icon = \"AstraDB\"\n    field_order = [\"token\", \"api_endpoint\", \"collection_name\", \"input_value\", \"embedding\"]\n\n    def build_config(self):\n        return {\n            \"search_type\": {\n                \"display_name\": \"Search Type\",\n                \"options\": [\"Similarity\", \"MMR\"],\n            },\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"Input value to search\",\n            },\n            \"embedding\": {\"display_name\": \"Embedding\", \"info\": \"Embedding to use\"},\n            \"collection_name\": {\n                \"display_name\": \"Collection Name\",\n                \"info\": \"The name of the collection within Astra DB where the vectors will be stored.\",\n            },\n            \"token\": {\n                \"display_name\": \"Token\",\n                \"info\": \"Authentication token for accessing Astra DB.\",\n                \"password\": True,\n            },\n            \"api_endpoint\": {\n                \"display_name\": \"API Endpoint\",\n                \"info\": \"API endpoint URL for the Astra DB service.\",\n            },\n            \"namespace\": {\n                \"display_name\": \"Namespace\",\n                \"info\": \"Optional namespace within Astra DB to use for the collection.\",\n                \"advanced\": True,\n            },\n            \"metric\": {\n                \"display_name\": \"Metric\",\n                \"info\": \"Optional distance metric for vector comparisons in the vector store.\",\n                \"advanced\": True,\n            },\n            \"batch_size\": {\n                \"display_name\": \"Batch Size\",\n                \"info\": \"Optional number of records to process in a single batch.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_batch_concurrency\": {\n                \"display_name\": \"Bulk Insert Batch Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_overwrite_concurrency\": {\n                \"display_name\": \"Bulk Insert Overwrite Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations that overwrite existing records.\",\n                \"advanced\": True,\n            },\n            \"bulk_delete_concurrency\": {\n                \"display_name\": \"Bulk Delete Concurrency\",\n                \"info\": \"Optional concurrency level for bulk delete operations.\",\n                \"advanced\": True,\n            },\n            \"setup_mode\": {\n                \"display_name\": \"Setup Mode\",\n                \"info\": \"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.\",\n                \"options\": [\"Sync\", \"Async\", \"Off\"],\n                \"advanced\": True,\n            },\n            \"pre_delete_collection\": {\n                \"display_name\": \"Pre Delete Collection\",\n                \"info\": \"Boolean flag to determine whether to delete the collection before creating a new one.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_include\": {\n                \"display_name\": \"Metadata Indexing Include\",\n                \"info\": \"Optional list of metadata fields to include in the indexing.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_exclude\": {\n                \"display_name\": \"Metadata Indexing Exclude\",\n                \"info\": \"Optional list of metadata fields to exclude from the indexing.\",\n                \"advanced\": True,\n            },\n            \"collection_indexing_policy\": {\n                \"display_name\": \"Collection Indexing Policy\",\n                \"info\": \"Optional dictionary defining the indexing policy for the collection.\",\n                \"advanced\": True,\n            },\n            \"number_of_results\": {\n                \"display_name\": \"Number of Results\",\n                \"info\": \"Number of results to return.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        embedding: Embeddings,\n        collection_name: str,\n        input_value: Text,\n        token: str,\n        api_endpoint: str,\n        search_type: str = \"Similarity\",\n        number_of_results: int = 4,\n        namespace: Optional[str] = None,\n        metric: Optional[str] = None,\n        batch_size: Optional[int] = None,\n        bulk_insert_batch_concurrency: Optional[int] = None,\n        bulk_insert_overwrite_concurrency: Optional[int] = None,\n        bulk_delete_concurrency: Optional[int] = None,\n        setup_mode: str = \"Sync\",\n        pre_delete_collection: bool = False,\n        metadata_indexing_include: Optional[List[str]] = None,\n        metadata_indexing_exclude: Optional[List[str]] = None,\n        collection_indexing_policy: Optional[dict] = None,\n    ) -> List[Record]:\n        vector_store = AstraDBVectorStoreComponent().build(\n            embedding=embedding,\n            collection_name=collection_name,\n            token=token,\n            api_endpoint=api_endpoint,\n            namespace=namespace,\n            metric=metric,\n            batch_size=batch_size,\n            bulk_insert_batch_concurrency=bulk_insert_batch_concurrency,\n            bulk_insert_overwrite_concurrency=bulk_insert_overwrite_concurrency,\n            bulk_delete_concurrency=bulk_delete_concurrency,\n            setup_mode=setup_mode,\n            pre_delete_collection=pre_delete_collection,\n            metadata_indexing_include=metadata_indexing_include,\n            metadata_indexing_exclude=metadata_indexing_exclude,\n            collection_indexing_policy=collection_indexing_policy,\n        )\n        try:\n            return self.search_with_vector_store(input_value, search_type, vector_store, k=number_of_results)\n        except KeyError as e:\n            if \"content\" in str(e):\n                raise ValueError(\n                    \"You should ingest data through Langflow (or LangChain) to query it in Langflow. Your collection does not contain a field name 'content'.\"\n                )\n            else:\n                raise e\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_indexing_policy":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_indexing_policy","display_name":"Collection Indexing Policy","advanced":true,"dynamic":false,"info":"Optional dictionary defining the indexing policy for the collection.","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"spotify_songs"},"metadata_indexing_exclude":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_exclude","display_name":"Metadata Indexing Exclude","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metadata_indexing_include":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_include","display_name":"Metadata Indexing Include","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metric":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metric","display_name":"Metric","advanced":true,"dynamic":false,"info":"Optional distance metric for vector comparisons in the vector store.","load_from_db":false,"title_case":false,"input_types":["Text"]},"namespace":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"namespace","display_name":"Namespace","advanced":true,"dynamic":false,"info":"Optional namespace within Astra DB to use for the collection.","load_from_db":false,"title_case":false,"input_types":["Text"]},"number_of_results":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":4,"fileTypes":[],"file_path":"","password":false,"name":"number_of_results","display_name":"Number of Results","advanced":true,"dynamic":false,"info":"Number of results to return.","load_from_db":false,"title_case":false},"pre_delete_collection":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"pre_delete_collection","display_name":"Pre Delete Collection","advanced":true,"dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","load_from_db":false,"title_case":false},"search_type":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Similarity","fileTypes":[],"file_path":"","password":false,"options":["Similarity","MMR"],"name":"search_type","display_name":"Search Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"setup_mode":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Sync","fileTypes":[],"file_path":"","password":false,"options":["Sync","Async","Off"],"name":"setup_mode","display_name":"Setup Mode","advanced":true,"dynamic":false,"info":"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.","load_from_db":false,"title_case":false,"input_types":["Text"]},"token":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"token","display_name":"Token","advanced":false,"dynamic":false,"info":"Authentication token for accessing Astra DB.","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"SPOTIFY_ASTRA_TOKEN"},"_type":"CustomComponent"},"description":"Searches an existing Astra DB Vector Store.","icon":"AstraDB","base_classes":["Record"],"display_name":"Astra DB Search","documentation":"","custom_fields":{"embedding":null,"collection_name":null,"input_value":null,"token":null,"api_endpoint":null,"search_type":null,"number_of_results":null,"namespace":null,"metric":null,"batch_size":null,"bulk_insert_batch_concurrency":null,"bulk_insert_overwrite_concurrency":null,"bulk_delete_concurrency":null,"setup_mode":null,"pre_delete_collection":null,"metadata_indexing_include":null,"metadata_indexing_exclude":null,"collection_indexing_policy":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":["token","api_endpoint","collection_name","input_value","embedding"],"beta":false},"id":"AstraDBSearch-yJfFU"},"selected":false,"width":384,"height":721,"positionAbsolute":{"x":-1019.7979236125238,"y":5458.228225992009},"dragging":false},{"id":"OpenAIEmbeddings-JTBUM","type":"genericNode","position":{"x":-1365.1102703783947,"y":6239.499334657861},"data":{"type":"OpenAIEmbeddings","node":{"template":{"allowed_special":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":[],"fileTypes":[],"file_path":"","password":false,"name":"allowed_special","display_name":"Allowed Special","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chunk_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1000,"fileTypes":[],"file_path":"","password":false,"name":"chunk_size","display_name":"Chunk Size","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Dict, List, Optional\n\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, NestedDict\n\n\nclass OpenAIEmbeddingsComponent(CustomComponent):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n\n    def build_config(self):\n        return {\n            \"allowed_special\": {\n                \"display_name\": \"Allowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"default_headers\": {\n                \"display_name\": \"Default Headers\",\n                \"advanced\": True,\n                \"field_type\": \"dict\",\n            },\n            \"default_query\": {\n                \"display_name\": \"Default Query\",\n                \"advanced\": True,\n                \"field_type\": \"NestedDict\",\n            },\n            \"disallowed_special\": {\n                \"display_name\": \"Disallowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"advanced\": True},\n            \"client\": {\"display_name\": \"Client\", \"advanced\": True},\n            \"deployment\": {\"display_name\": \"Deployment\", \"advanced\": True},\n            \"embedding_ctx_length\": {\n                \"display_name\": \"Embedding Context Length\",\n                \"advanced\": True,\n            },\n            \"max_retries\": {\"display_name\": \"Max Retries\", \"advanced\": True},\n            \"model\": {\n                \"display_name\": \"Model\",\n                \"advanced\": False,\n                \"options\": [\n                    \"text-embedding-3-small\",\n                    \"text-embedding-3-large\",\n                    \"text-embedding-ada-002\",\n                ],\n            },\n            \"model_kwargs\": {\"display_name\": \"Model Kwargs\", \"advanced\": True},\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"password\": True,\n                \"advanced\": True,\n            },\n            \"openai_api_key\": {\"display_name\": \"OpenAI API Key\", \"password\": True},\n            \"openai_api_type\": {\n                \"display_name\": \"OpenAI API Type\",\n                \"advanced\": True,\n                \"password\": True,\n            },\n            \"openai_api_version\": {\n                \"display_name\": \"OpenAI API Version\",\n                \"advanced\": True,\n            },\n            \"openai_organization\": {\n                \"display_name\": \"OpenAI Organization\",\n                \"advanced\": True,\n            },\n            \"openai_proxy\": {\"display_name\": \"OpenAI Proxy\", \"advanced\": True},\n            \"request_timeout\": {\"display_name\": \"Request Timeout\", \"advanced\": True},\n            \"show_progress_bar\": {\n                \"display_name\": \"Show Progress Bar\",\n                \"advanced\": True,\n            },\n            \"skip_empty\": {\"display_name\": \"Skip Empty\", \"advanced\": True},\n            \"tiktoken_model_name\": {\n                \"display_name\": \"TikToken Model Name\",\n                \"advanced\": True,\n            },\n            \"tiktoken_enable\": {\"display_name\": \"TikToken Enable\", \"advanced\": True},\n        }\n\n    def build(\n        self,\n        openai_api_key: str,\n        default_headers: Optional[Dict[str, str]] = None,\n        default_query: Optional[NestedDict] = {},\n        allowed_special: List[str] = [],\n        disallowed_special: List[str] = [\"all\"],\n        chunk_size: int = 1000,\n        deployment: str = \"text-embedding-ada-002\",\n        embedding_ctx_length: int = 8191,\n        max_retries: int = 6,\n        model: str = \"text-embedding-ada-002\",\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        openai_api_type: Optional[str] = None,\n        openai_api_version: Optional[str] = None,\n        openai_organization: Optional[str] = None,\n        openai_proxy: Optional[str] = None,\n        request_timeout: Optional[float] = None,\n        show_progress_bar: bool = False,\n        skip_empty: bool = False,\n        tiktoken_enable: bool = True,\n        tiktoken_model_name: Optional[str] = None,\n    ) -> Embeddings:\n        # This is to avoid errors with Vector Stores (e.g Chroma)\n        if disallowed_special == [\"all\"]:\n            disallowed_special = \"all\"  # type: ignore\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        return OpenAIEmbeddings(\n            tiktoken_enabled=tiktoken_enable,\n            default_headers=default_headers,\n            default_query=default_query,\n            allowed_special=set(allowed_special),\n            disallowed_special=\"all\",\n            chunk_size=chunk_size,\n            deployment=deployment,\n            embedding_ctx_length=embedding_ctx_length,\n            max_retries=max_retries,\n            model=model,\n            model_kwargs=model_kwargs,\n            base_url=openai_api_base,\n            api_key=api_key,\n            openai_api_type=openai_api_type,\n            api_version=openai_api_version,\n            organization=openai_organization,\n            openai_proxy=openai_proxy,\n            timeout=request_timeout,\n            show_progress_bar=show_progress_bar,\n            skip_empty=skip_empty,\n            tiktoken_model_name=tiktoken_model_name,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"default_headers":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"default_headers","display_name":"Default Headers","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"default_query":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"default_query","display_name":"Default Query","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"deployment":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"text-embedding-ada-002","fileTypes":[],"file_path":"","password":false,"name":"deployment","display_name":"Deployment","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"disallowed_special":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":["all"],"fileTypes":[],"file_path":"","password":false,"name":"disallowed_special","display_name":"Disallowed Special","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"embedding_ctx_length":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":8191,"fileTypes":[],"file_path":"","password":false,"name":"embedding_ctx_length","display_name":"Embedding Context Length","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"max_retries":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":6,"fileTypes":[],"file_path":"","password":false,"name":"max_retries","display_name":"Max Retries","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"text-embedding-ada-002","fileTypes":[],"file_path":"","password":false,"options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"name":"model","display_name":"Model","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"OPENAI_KEY"},"openai_api_type":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_type","display_name":"OpenAI API Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"openai_api_version":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_version","display_name":"OpenAI API Version","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_organization":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_organization","display_name":"OpenAI Organization","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_proxy":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_proxy","display_name":"OpenAI Proxy","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"request_timeout":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"request_timeout","display_name":"Request Timeout","advanced":true,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"show_progress_bar":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"show_progress_bar","display_name":"Show Progress Bar","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"skip_empty":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"skip_empty","display_name":"Skip Empty","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"tiktoken_enable":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"tiktoken_enable","display_name":"TikToken Enable","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"tiktoken_model_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tiktoken_model_name","display_name":"TikToken Model Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Generate embeddings using OpenAI models.","base_classes":["Embeddings"],"display_name":"OpenAI Embeddings","documentation":"","custom_fields":{"openai_api_key":null,"default_headers":null,"default_query":null,"allowed_special":null,"disallowed_special":null,"chunk_size":null,"deployment":null,"embedding_ctx_length":null,"max_retries":null,"model":null,"model_kwargs":null,"openai_api_base":null,"openai_api_type":null,"openai_api_version":null,"openai_organization":null,"openai_proxy":null,"request_timeout":null,"show_progress_bar":null,"skip_empty":null,"tiktoken_enable":null,"tiktoken_model_name":null},"output_types":["Embeddings"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"OpenAIEmbeddings-JTBUM"},"selected":true,"width":384,"height":391,"positionAbsolute":{"x":-1365.1102703783947,"y":6239.499334657861},"dragging":false},{"id":"AstraDB-b9hPF","type":"genericNode","position":{"x":-627.6266009098007,"y":7174.149351555424},"data":{"type":"AstraDB","node":{"template":{"embedding":{"type":"Embeddings","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"embedding","display_name":"Embedding","advanced":false,"dynamic":false,"info":"Embedding to use","load_from_db":false,"title_case":false},"inputs":{"type":"Record","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","display_name":"Inputs","advanced":false,"dynamic":false,"info":"Optional list of records to be processed and stored in the vector store.","load_from_db":false,"title_case":false},"api_endpoint":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"api_endpoint","display_name":"API Endpoint","advanced":false,"dynamic":false,"info":"API endpoint URL for the Astra DB service.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"https://dfa19251-eb15-46c4-8602-1997dd83fe7a-us-east-2.apps.astra.datastax.com"},"batch_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"batch_size","display_name":"Batch Size","advanced":true,"dynamic":false,"info":"Optional number of records to process in a single batch.","load_from_db":false,"title_case":false},"bulk_delete_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_delete_concurrency","display_name":"Bulk Delete Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk delete operations.","load_from_db":false,"title_case":false},"bulk_insert_batch_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_batch_concurrency","display_name":"Bulk Insert Batch Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations.","load_from_db":false,"title_case":false},"bulk_insert_overwrite_concurrency":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"bulk_insert_overwrite_concurrency","display_name":"Bulk Insert Overwrite Concurrency","advanced":true,"dynamic":false,"info":"Optional concurrency level for bulk insert operations that overwrite existing records.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional, Union\nfrom langchain_astradb import AstraDBVectorStore\nfrom langchain_astradb.utils.astradb import SetupMode\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, VectorStore\nfrom langflow.schema import Record\nfrom langchain_core.retrievers import BaseRetriever\n\n\nclass AstraDBVectorStoreComponent(CustomComponent):\n    display_name = \"Astra DB\"\n    description = \"Builds or loads an Astra DB Vector Store.\"\n    icon = \"AstraDB\"\n    field_order = [\"token\", \"api_endpoint\", \"collection_name\", \"inputs\", \"embedding\"]\n\n    def build_config(self):\n        return {\n            \"inputs\": {\n                \"display_name\": \"Inputs\",\n                \"info\": \"Optional list of records to be processed and stored in the vector store.\",\n            },\n            \"embedding\": {\"display_name\": \"Embedding\", \"info\": \"Embedding to use\"},\n            \"collection_name\": {\n                \"display_name\": \"Collection Name\",\n                \"info\": \"The name of the collection within Astra DB where the vectors will be stored.\",\n            },\n            \"token\": {\n                \"display_name\": \"Token\",\n                \"info\": \"Authentication token for accessing Astra DB.\",\n                \"password\": True,\n            },\n            \"api_endpoint\": {\n                \"display_name\": \"API Endpoint\",\n                \"info\": \"API endpoint URL for the Astra DB service.\",\n            },\n            \"namespace\": {\n                \"display_name\": \"Namespace\",\n                \"info\": \"Optional namespace within Astra DB to use for the collection.\",\n                \"advanced\": True,\n            },\n            \"metric\": {\n                \"display_name\": \"Metric\",\n                \"info\": \"Optional distance metric for vector comparisons in the vector store.\",\n                \"advanced\": True,\n            },\n            \"batch_size\": {\n                \"display_name\": \"Batch Size\",\n                \"info\": \"Optional number of records to process in a single batch.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_batch_concurrency\": {\n                \"display_name\": \"Bulk Insert Batch Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations.\",\n                \"advanced\": True,\n            },\n            \"bulk_insert_overwrite_concurrency\": {\n                \"display_name\": \"Bulk Insert Overwrite Concurrency\",\n                \"info\": \"Optional concurrency level for bulk insert operations that overwrite existing records.\",\n                \"advanced\": True,\n            },\n            \"bulk_delete_concurrency\": {\n                \"display_name\": \"Bulk Delete Concurrency\",\n                \"info\": \"Optional concurrency level for bulk delete operations.\",\n                \"advanced\": True,\n            },\n            \"setup_mode\": {\n                \"display_name\": \"Setup Mode\",\n                \"info\": \"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.\",\n                \"options\": [\"Sync\", \"Async\", \"Off\"],\n                \"advanced\": True,\n            },\n            \"pre_delete_collection\": {\n                \"display_name\": \"Pre Delete Collection\",\n                \"info\": \"Boolean flag to determine whether to delete the collection before creating a new one.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_include\": {\n                \"display_name\": \"Metadata Indexing Include\",\n                \"info\": \"Optional list of metadata fields to include in the indexing.\",\n                \"advanced\": True,\n            },\n            \"metadata_indexing_exclude\": {\n                \"display_name\": \"Metadata Indexing Exclude\",\n                \"info\": \"Optional list of metadata fields to exclude from the indexing.\",\n                \"advanced\": True,\n            },\n            \"collection_indexing_policy\": {\n                \"display_name\": \"Collection Indexing Policy\",\n                \"info\": \"Optional dictionary defining the indexing policy for the collection.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        embedding: Embeddings,\n        token: str,\n        api_endpoint: str,\n        collection_name: str,\n        inputs: Optional[List[Record]] = None,\n        namespace: Optional[str] = None,\n        metric: Optional[str] = None,\n        batch_size: Optional[int] = None,\n        bulk_insert_batch_concurrency: Optional[int] = None,\n        bulk_insert_overwrite_concurrency: Optional[int] = None,\n        bulk_delete_concurrency: Optional[int] = None,\n        setup_mode: str = \"Sync\",\n        pre_delete_collection: bool = False,\n        metadata_indexing_include: Optional[List[str]] = None,\n        metadata_indexing_exclude: Optional[List[str]] = None,\n        collection_indexing_policy: Optional[dict] = None,\n    ) -> Union[VectorStore, BaseRetriever]:\n        try:\n            setup_mode_value = SetupMode[setup_mode.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid setup mode: {setup_mode}\")\n        if inputs:\n            documents = []\n            for _input in inputs:\n                if isinstance(_input, str):\n                    # If _input is a string, create a Document instance from it\n                    document = Document(_input)\n                    documents.append(document)\n                elif hasattr(_input, 'to_lc_document') and callable(_input.to_lc_document):\n                    # If _input has to_lc_document method, use it to convert to document\n                    documents.append(_input.to_lc_document())\n                else:\n                    print(f\"Cannot convert {_input} to a Document.\")\n\n            vector_store = AstraDBVectorStore.from_documents(\n                documents=documents,\n                embedding=embedding,\n                collection_name=collection_name,\n                token=token,\n                api_endpoint=api_endpoint,\n                namespace=namespace,\n                metric=metric,\n                batch_size=batch_size,\n                bulk_insert_batch_concurrency=bulk_insert_batch_concurrency,\n                bulk_insert_overwrite_concurrency=bulk_insert_overwrite_concurrency,\n                bulk_delete_concurrency=bulk_delete_concurrency,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=pre_delete_collection,\n                metadata_indexing_include=metadata_indexing_include,\n                metadata_indexing_exclude=metadata_indexing_exclude,\n                collection_indexing_policy=collection_indexing_policy,\n            )\n        else:\n            vector_store = AstraDBVectorStore(\n                embedding=embedding,\n                collection_name=collection_name,\n                token=token,\n                api_endpoint=api_endpoint,\n                namespace=namespace,\n                metric=metric,\n                batch_size=batch_size,\n                bulk_insert_batch_concurrency=bulk_insert_batch_concurrency,\n                bulk_insert_overwrite_concurrency=bulk_insert_overwrite_concurrency,\n                bulk_delete_concurrency=bulk_delete_concurrency,\n                setup_mode=setup_mode_value,\n                pre_delete_collection=pre_delete_collection,\n                metadata_indexing_include=metadata_indexing_include,\n                metadata_indexing_exclude=metadata_indexing_exclude,\n                collection_indexing_policy=collection_indexing_policy,\n            )\n\n        return vector_store\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"collection_indexing_policy":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_indexing_policy","display_name":"Collection Indexing Policy","advanced":true,"dynamic":false,"info":"Optional dictionary defining the indexing policy for the collection.","load_from_db":false,"title_case":false},"collection_name":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"collection_name","display_name":"Collection Name","advanced":false,"dynamic":false,"info":"The name of the collection within Astra DB where the vectors will be stored.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"spotify_songs"},"metadata_indexing_exclude":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_exclude","display_name":"Metadata Indexing Exclude","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to exclude from the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metadata_indexing_include":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metadata_indexing_include","display_name":"Metadata Indexing Include","advanced":true,"dynamic":false,"info":"Optional list of metadata fields to include in the indexing.","load_from_db":false,"title_case":false,"input_types":["Text"]},"metric":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"metric","display_name":"Metric","advanced":true,"dynamic":false,"info":"Optional distance metric for vector comparisons in the vector store.","load_from_db":false,"title_case":false,"input_types":["Text"]},"namespace":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"namespace","display_name":"Namespace","advanced":true,"dynamic":false,"info":"Optional namespace within Astra DB to use for the collection.","load_from_db":false,"title_case":false,"input_types":["Text"]},"pre_delete_collection":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"pre_delete_collection","display_name":"Pre Delete Collection","advanced":true,"dynamic":false,"info":"Boolean flag to determine whether to delete the collection before creating a new one.","load_from_db":false,"title_case":false},"setup_mode":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Sync","fileTypes":[],"file_path":"","password":false,"options":["Sync","Async","Off"],"name":"setup_mode","display_name":"Setup Mode","advanced":true,"dynamic":false,"info":"Configuration mode for setting up the vector store, with options like “Sync”, “Async”, or “Off”.","load_from_db":false,"title_case":false,"input_types":["Text"]},"token":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"token","display_name":"Token","advanced":false,"dynamic":false,"info":"Authentication token for accessing Astra DB.","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"SPOTIFY_ASTRA_TOKEN"},"_type":"CustomComponent"},"description":"Builds or loads an Astra DB Vector Store.","icon":"AstraDB","base_classes":["BaseRetriever","Generic","object","Runnable","RunnableSerializable","Serializable","VectorStore"],"display_name":"Astra DB","documentation":"","custom_fields":{"embedding":null,"token":null,"api_endpoint":null,"collection_name":null,"inputs":null,"namespace":null,"metric":null,"batch_size":null,"bulk_insert_batch_concurrency":null,"bulk_insert_overwrite_concurrency":null,"bulk_delete_concurrency":null,"setup_mode":null,"pre_delete_collection":null,"metadata_indexing_include":null,"metadata_indexing_exclude":null,"collection_indexing_policy":null},"output_types":["VectorStore","BaseRetriever"],"field_formatters":{},"frozen":false,"field_order":["token","api_endpoint","collection_name","inputs","embedding"],"beta":false},"id":"AstraDB-b9hPF","description":"Builds or loads an Astra DB Vector Store.","display_name":"Astra DB"},"selected":false,"width":384,"height":581,"positionAbsolute":{"x":-627.6266009098007,"y":7174.149351555424},"dragging":false},{"id":"OpenAIEmbeddings-3lzO1","type":"genericNode","position":{"x":-182.33517210997263,"y":6855.474156496537},"data":{"type":"OpenAIEmbeddings","node":{"template":{"allowed_special":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":[],"fileTypes":[],"file_path":"","password":false,"name":"allowed_special","display_name":"Allowed Special","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"chunk_size":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":1000,"fileTypes":[],"file_path":"","password":false,"name":"chunk_size","display_name":"Chunk Size","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Dict, List, Optional\n\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Embeddings, NestedDict\n\n\nclass OpenAIEmbeddingsComponent(CustomComponent):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n\n    def build_config(self):\n        return {\n            \"allowed_special\": {\n                \"display_name\": \"Allowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"default_headers\": {\n                \"display_name\": \"Default Headers\",\n                \"advanced\": True,\n                \"field_type\": \"dict\",\n            },\n            \"default_query\": {\n                \"display_name\": \"Default Query\",\n                \"advanced\": True,\n                \"field_type\": \"NestedDict\",\n            },\n            \"disallowed_special\": {\n                \"display_name\": \"Disallowed Special\",\n                \"advanced\": True,\n                \"field_type\": \"str\",\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\"display_name\": \"Chunk Size\", \"advanced\": True},\n            \"client\": {\"display_name\": \"Client\", \"advanced\": True},\n            \"deployment\": {\"display_name\": \"Deployment\", \"advanced\": True},\n            \"embedding_ctx_length\": {\n                \"display_name\": \"Embedding Context Length\",\n                \"advanced\": True,\n            },\n            \"max_retries\": {\"display_name\": \"Max Retries\", \"advanced\": True},\n            \"model\": {\n                \"display_name\": \"Model\",\n                \"advanced\": False,\n                \"options\": [\n                    \"text-embedding-3-small\",\n                    \"text-embedding-3-large\",\n                    \"text-embedding-ada-002\",\n                ],\n            },\n            \"model_kwargs\": {\"display_name\": \"Model Kwargs\", \"advanced\": True},\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"password\": True,\n                \"advanced\": True,\n            },\n            \"openai_api_key\": {\"display_name\": \"OpenAI API Key\", \"password\": True},\n            \"openai_api_type\": {\n                \"display_name\": \"OpenAI API Type\",\n                \"advanced\": True,\n                \"password\": True,\n            },\n            \"openai_api_version\": {\n                \"display_name\": \"OpenAI API Version\",\n                \"advanced\": True,\n            },\n            \"openai_organization\": {\n                \"display_name\": \"OpenAI Organization\",\n                \"advanced\": True,\n            },\n            \"openai_proxy\": {\"display_name\": \"OpenAI Proxy\", \"advanced\": True},\n            \"request_timeout\": {\"display_name\": \"Request Timeout\", \"advanced\": True},\n            \"show_progress_bar\": {\n                \"display_name\": \"Show Progress Bar\",\n                \"advanced\": True,\n            },\n            \"skip_empty\": {\"display_name\": \"Skip Empty\", \"advanced\": True},\n            \"tiktoken_model_name\": {\n                \"display_name\": \"TikToken Model Name\",\n                \"advanced\": True,\n            },\n            \"tiktoken_enable\": {\"display_name\": \"TikToken Enable\", \"advanced\": True},\n        }\n\n    def build(\n        self,\n        openai_api_key: str,\n        default_headers: Optional[Dict[str, str]] = None,\n        default_query: Optional[NestedDict] = {},\n        allowed_special: List[str] = [],\n        disallowed_special: List[str] = [\"all\"],\n        chunk_size: int = 1000,\n        deployment: str = \"text-embedding-ada-002\",\n        embedding_ctx_length: int = 8191,\n        max_retries: int = 6,\n        model: str = \"text-embedding-ada-002\",\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        openai_api_type: Optional[str] = None,\n        openai_api_version: Optional[str] = None,\n        openai_organization: Optional[str] = None,\n        openai_proxy: Optional[str] = None,\n        request_timeout: Optional[float] = None,\n        show_progress_bar: bool = False,\n        skip_empty: bool = False,\n        tiktoken_enable: bool = True,\n        tiktoken_model_name: Optional[str] = None,\n    ) -> Embeddings:\n        # This is to avoid errors with Vector Stores (e.g Chroma)\n        if disallowed_special == [\"all\"]:\n            disallowed_special = \"all\"  # type: ignore\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        return OpenAIEmbeddings(\n            tiktoken_enabled=tiktoken_enable,\n            default_headers=default_headers,\n            default_query=default_query,\n            allowed_special=set(allowed_special),\n            disallowed_special=\"all\",\n            chunk_size=chunk_size,\n            deployment=deployment,\n            embedding_ctx_length=embedding_ctx_length,\n            max_retries=max_retries,\n            model=model,\n            model_kwargs=model_kwargs,\n            base_url=openai_api_base,\n            api_key=api_key,\n            openai_api_type=openai_api_type,\n            api_version=openai_api_version,\n            organization=openai_organization,\n            openai_proxy=openai_proxy,\n            timeout=request_timeout,\n            show_progress_bar=show_progress_bar,\n            skip_empty=skip_empty,\n            tiktoken_model_name=tiktoken_model_name,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"default_headers":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"default_headers","display_name":"Default Headers","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"default_query":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"default_query","display_name":"Default Query","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"deployment":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"text-embedding-ada-002","fileTypes":[],"file_path":"","password":false,"name":"deployment","display_name":"Deployment","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"disallowed_special":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":["all"],"fileTypes":[],"file_path":"","password":false,"name":"disallowed_special","display_name":"Disallowed Special","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"embedding_ctx_length":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":8191,"fileTypes":[],"file_path":"","password":false,"name":"embedding_ctx_length","display_name":"Embedding Context Length","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"max_retries":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":6,"fileTypes":[],"file_path":"","password":false,"name":"max_retries","display_name":"Max Retries","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"text-embedding-ada-002","fileTypes":[],"file_path":"","password":false,"options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"name":"model","display_name":"Model","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"OPENAI_KEY"},"openai_api_type":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_type","display_name":"OpenAI API Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"openai_api_version":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_version","display_name":"OpenAI API Version","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_organization":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_organization","display_name":"OpenAI Organization","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_proxy":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_proxy","display_name":"OpenAI Proxy","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"request_timeout":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"request_timeout","display_name":"Request Timeout","advanced":true,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"show_progress_bar":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"show_progress_bar","display_name":"Show Progress Bar","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"skip_empty":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"skip_empty","display_name":"Skip Empty","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"tiktoken_enable":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":true,"fileTypes":[],"file_path":"","password":false,"name":"tiktoken_enable","display_name":"TikToken Enable","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"tiktoken_model_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tiktoken_model_name","display_name":"TikToken Model Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Generate embeddings using OpenAI models.","base_classes":["Embeddings"],"display_name":"OpenAI Embeddings","documentation":"","custom_fields":{"openai_api_key":null,"default_headers":null,"default_query":null,"allowed_special":null,"disallowed_special":null,"chunk_size":null,"deployment":null,"embedding_ctx_length":null,"max_retries":null,"model":null,"model_kwargs":null,"openai_api_base":null,"openai_api_type":null,"openai_api_version":null,"openai_organization":null,"openai_proxy":null,"request_timeout":null,"show_progress_bar":null,"skip_empty":null,"tiktoken_enable":null,"tiktoken_model_name":null},"output_types":["Embeddings"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"OpenAIEmbeddings-3lzO1"},"selected":false,"width":384,"height":391,"positionAbsolute":{"x":-182.33517210997263,"y":6855.474156496537},"dragging":false},{"id":"ChatOutput-xZCSP","type":"genericNode","position":{"x":561.7549291997086,"y":5740.376468549698},"data":{"type":"ChatOutput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"input_value":{"type":"Union[str, Message, Record]","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"input_types":["Text","Record","Message"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[Union[str, Message, Record]] = None,\n        session_id: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        return_message: Optional[bool] = False,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            files=files,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Message","advanced":true,"dynamic":false,"info":"Return the message as a Message containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message","object","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"files":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"id":"ChatOutput-xZCSP","description":"Display a chat message in the Playground.","display_name":"Chat Output","edited":false},"selected":false,"width":384,"height":251,"positionAbsolute":{"x":561.7549291997086,"y":5740.376468549698},"dragging":false},{"id":"CustomComponent-hp3I4","type":"genericNode","position":{"x":-2559.3989427914757,"y":6892.501801022365},"data":{"type":"CustomComponent","node":{"template":{"access_token":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"access_token","display_name":"Access Token","advanced":false,"dynamic":false,"info":"Spotify API access token with necessary scopes.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"BQAt2ph9iao1x454BPsyJN9jkgcO0AEAatHmzcMgB0eJhKiDeJFuGxQMtyyaSe3WfBqpcqXblue9DQee3HtjCWAfkADyWlHv1BPTtfDZpIx6ChrWRwA"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import requests\nfrom langflow import CustomComponent\nfrom typing import List\nfrom loguru import logger\n\nclass AudioFeaturesExtractor(CustomComponent):\n    display_name = \"Audio Features Extractor\"\n    description = \"Extracts audio features of each track in a Spotify playlist and generates textual descriptions.\"\n    output_types = [\"Text\"]\n\n    field_config = {\n        \"playlist_id\": {\n            \"display_name\": \"Playlist ID\",\n            \"info\": \"ID of the Spotify playlist from which to extract audio features.\"\n        },\n        \"access_token\": {\n            \"display_name\": \"Access Token\",\n            \"info\": \"Spotify API access token with necessary scopes.\"\n        }\n    }\n\n    async def build(\n        self,\n        playlist_id: str,\n        access_token: str,\n    ) -> List[str]:\n        headers = {\n            \"Authorization\": f\"Bearer {access_token}\"\n        }\n        \n        SPOTIFY_API_BASE = \"https://api.spotify.com/v1\"\n\n        try:\n            # Get playlist tracks\n            response = requests.get(f\"{SPOTIFY_API_BASE}/playlists/{playlist_id}/tracks\", headers=headers)\n            response.raise_for_status()\n            playlist_tracks = response.json()[\"items\"]\n            \n            textual_descriptions = []\n            \n            # Iterate over tracks and fetch audio features\n            for track in playlist_tracks:\n                track_info = track[\"track\"]\n                track_id = track_info[\"id\"]\n                \n                # Get track details (name and artist)\n                response = requests.get(f\"{SPOTIFY_API_BASE}/tracks/{track_id}\", headers=headers)\n                response.raise_for_status()\n                track_details = response.json()\n                \n                # Get track audio features\n                response = requests.get(f\"{SPOTIFY_API_BASE}/audio-features/{track_id}\", headers=headers)\n                response.raise_for_status()\n                audio_features = response.json()\n                \n                # Generate textual description\n                description = (\n                    f\"Track: {track_details['name']} by {track_details['artists'][0]['name'] if track_details['artists'] else 'Unknown Artist'}\\n\"\n                    f\"Danceability: {audio_features['danceability']}, Energy: {audio_features['energy']}, \"\n                    f\"Loudness: {audio_features['loudness']} dB, Speechiness: {audio_features['speechiness']}, \"\n                    f\"Acousticness: {audio_features['acousticness']}, Instrumentalness: {audio_features['instrumentalness']}, \"\n                    f\"Liveness: {audio_features['liveness']}, Valence: {audio_features['valence']}, Tempo: {audio_features['tempo']} BPM, \"\n                    f\"Duration: {audio_features['duration_ms'] / 1000} seconds, Time Signature: {audio_features['time_signature']}/4\"\n                )\n                \n                textual_descriptions.append(description)\n            \n            return textual_descriptions\n        \n        except Exception as e:\n            logger.error(f\"Error extracting audio features: {e}\")\n            raise\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"playlist_id":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"playlist_id","display_name":"Playlist ID","advanced":false,"dynamic":false,"info":"ID of the Spotify playlist from which to extract audio features.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"37i9dQZEVXbLRQDuF5jeBp"},"_type":"CustomComponent"},"description":"Extracts audio features of each track in a Spotify playlist and generates textual descriptions.","base_classes":["object","str","Text"],"display_name":"Spotify Audio","documentation":"","custom_fields":{"playlist_id":null,"access_token":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["playlist_id","access_token"],"beta":false,"edited":true},"id":"CustomComponent-hp3I4","description":"Extracts audio features of each track in a Spotify playlist and generates textual descriptions.","display_name":"Spotify Audio"},"selected":false,"width":384,"height":447,"dragging":false,"positionAbsolute":{"x":-2559.3989427914757,"y":6892.501801022365}},{"id":"Prompt-Ev0wU","type":"genericNode","position":{"x":-1851.355091113431,"y":6941.854624947312},"data":{"type":"Prompt","node":{"template":{"inputs":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"inputs","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List\nfrom langchain_core.prompts import PromptTemplate\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Prompt, TemplateField, Text\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        inputs: List[Text],  # List of input texts\n        template: Prompt,\n        **kwargs,\n    ) -> List[Text]:\n        from langflow.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        prompts = []\n\n        for text in inputs:\n            kwargs['user_input'] = text  # Assign each input text to 'user_input'\n            kwargs_str = dict_values_to_string(kwargs)\n            kwargs_str = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs_str.items()}\n            try:\n                formatted_prompt = prompt_template.format(**kwargs_str)\n                prompts.append(Text(formatted_prompt))\n            except Exception as exc:\n                raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n\n        self.status = f'Generated {len(prompts)} prompts'\n        return prompts\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"Create a 2-3 sentence textual description of a song interpreting the following information: {user_input}","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Create a prompt template with dynamic variables.","icon":"prompts","base_classes":["object","str","Text"],"display_name":"Prompt","documentation":"","custom_fields":{"inputs":null,"template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":false},"id":"Prompt-Ev0wU","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":411,"positionAbsolute":{"x":-1851.355091113431,"y":6941.854624947312},"dragging":false},{"id":"OpenAIModel-IfDFk","type":"genericNode","position":{"x":-1109.5339039003766,"y":6878.957707981927},"data":{"type":"OpenAIModel","node":{"template":{"input_values":{"type":"str","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_values","display_name":"Input Values","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import NestedDict, Text\nfrom langflow.schema import Record\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n\n    field_order = [\n        \"max_tokens\",\n        \"model_kwargs\",\n        \"model_name\",\n        \"openai_api_base\",\n        \"openai_api_key\",\n        \"temperature\",\n        \"input_values\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_values\": {\"display_name\": \"Input Values\"},\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"advanced\": False,\n                \"options\": MODEL_NAMES,  # Ensure MODEL_NAMES is imported or defined correctly\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": True,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"info\": \"The OpenAI API Key to use for the OpenAI model.\",\n                \"advanced\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"value\": 0.1,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_values: List[Text],\n        openai_api_key: str,\n        temperature: float,\n        model_name: str = \"gpt-4o\",\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> List[Record]:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        outputs = []\n        for input_value in input_values:\n            output = ChatOpenAI(\n                max_tokens=max_tokens or None,\n                model_kwargs=model_kwargs,\n                model=model_name,\n                base_url=openai_api_base,\n                api_key=api_key,\n                temperature=temperature,\n            )\n            generated_text = self.get_chat_result(output, stream, input_value, system_message)\n            outputs.append(Record(content=generated_text))\n        \n        return outputs\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":256,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-3.5-turbo","fileTypes":[],"file_path":"","password":false,"options":["llama3-8b-8192","llama3-70b-8192","mixtral-8x7b-32768","gemma-7b-it"],"name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"OPENAI_KEY"},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.1,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["Record"],"display_name":"OpenAI","documentation":"","custom_fields":{"input_values":null,"openai_api_key":null,"temperature":null,"model_name":null,"max_tokens":null,"model_kwargs":null,"openai_api_base":null,"stream":null,"system_message":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":["max_tokens","model_kwargs","model_name","openai_api_base","openai_api_key","temperature","input_values","system_message","stream"],"beta":false,"edited":true},"id":"OpenAIModel-IfDFk","description":"Generates text using OpenAI LLMs.","display_name":"OpenAI"},"selected":false,"width":384,"height":563,"positionAbsolute":{"x":-1109.5339039003766,"y":6878.957707981927},"dragging":false},{"id":"RecordsToText-5RagF","type":"genericNode","position":{"x":-641.4016510126921,"y":6138.912782861232},"data":{"type":"RecordsToText","node":{"template":{"records":{"type":"Record","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"records","display_name":"Records","advanced":false,"dynamic":false,"info":"The records to convert to text.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.field_typing import Text\nfrom langflow.helpers.record import records_to_text\nfrom langflow.schema import Record\n\n\nclass RecordsToTextComponent(CustomComponent):\n    display_name = \"Records To Text\"\n    description = \"Convert Records into plain text following a specified template.\"\n\n    def build_config(self):\n        return {\n            \"records\": {\n                \"display_name\": \"Records\",\n                \"info\": \"The records to convert to text.\",\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"info\": \"The template to use for formatting the records. It can contain the keys {text}, {data} or any other key in the Record.\",\n                \"multiline\": True,\n            },\n        }\n\n    def build(\n        self,\n        records: list[Record],\n        template: str = \"Text: {text}\\nData: {data}\",\n    ) -> Text:\n        if not records:\n            return \"\"\n        if isinstance(records, Record):\n            records = [records]\n\n        result_string = records_to_text(template, records)\n        self.status = result_string\n        return result_string\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"Text: {text}\\nData: {data}","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"The template to use for formatting the records. It can contain the keys {text}, {data} or any other key in the Record.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Convert Records into plain text following a specified template.","base_classes":["object","str","Text"],"display_name":"Records To Text","documentation":"","custom_fields":{"records":null,"template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"id":"RecordsToText-5RagF","description":"Convert Records into plain text following a specified template.","display_name":"Records To Text","edited":false},"selected":false,"width":384,"height":373,"positionAbsolute":{"x":-641.4016510126921,"y":6138.912782861232},"dragging":false},{"id":"ChatInput-TfPvB","type":"genericNode","position":{"x":-2330.6729222858867,"y":6181.857587721836},"data":{"type":"ChatInput","node":{"template":{"files":{"type":"file","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[".txt",".md",".mdx",".csv",".json",".yaml",".yml",".xml",".html",".htm",".pdf",".docx",".py",".sh",".sql",".js",".ts",".tsx",".jpg",".jpeg",".png",".bmp"],"file_path":"","password":false,"name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","load_from_db":false,"title_case":false,"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.schema.message import Message\nfrom langflow.field_typing import Text\nfrom typing import Union\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"display_name\": \"Text\",\n            \"multiline\": True,\n        }\n        build_config[\"return_message\"] = {\n            \"display_name\": \"Return Record\",\n            \"advanced\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        files: Optional[list[str]] = None,\n        session_id: Optional[str] = None,\n        return_message: Optional[bool] = False,\n    ) -> Union[Message, Text]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            files=files,\n            session_id=session_id,\n            return_message=return_message,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Text","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"can you recommend me an acoustic song"},"return_message":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_message","display_name":"Return Record","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message","object","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"files":null,"session_id":null,"return_message":null},"output_types":["Message","Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"name":"Chat Input"},"id":"ChatInput-TfPvB"},"selected":false,"width":384,"height":297,"positionAbsolute":{"x":-2330.6729222858867,"y":6181.857587721836},"dragging":false},{"id":"CustomComponent-Tddks","type":"genericNode","position":{"x":-1651.2504296184306,"y":5513.0145249745065},"data":{"type":"CustomComponent","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow import CustomComponent\n\nclass KeywordIdentifier(CustomComponent):\n    display_name = \"Keyword Identifier\"\n    description = \"Sorts keywords into genre, event, single recommendation, or generic query categories.\"\n\n    def build_config(self):\n        return {\n            \"query\": {\"display_name\": \"User Query\"}\n        }\n\n    def build(self, query: str) -> str:\n        return self.classify_query(query)\n\n    def classify_query(self, query):\n        # Define keywords or phrases for each category\n        genre_keywords = {\"genre\", \"type\", \"kind\"}\n        event_keywords = {\"event\", \"party\", \"wedding\", \"workout\", \"study\", \"relax\", \"birthday\", \"dinner\", \"gathering\"}\n        recommendation_keywords = {\"suggest\", \"play\"}\n        \n        # Initialize flags for each category\n        is_genre = any(keyword in query.lower() for keyword in genre_keywords)\n        is_event = any(keyword in query.lower() for keyword in event_keywords)\n        is_recommendation = any(keyword in query.lower() for keyword in recommendation_keywords)\n        \n        # Determine the category based on flags\n        if is_genre:\n            return \"Context information is below.---------------------{contex}---------------------Given the context information and not prior knowledge, answer the query with a bulleted song playlist and a short description of the genre.Query: {query_str}Answer: \"\n        elif is_event:\n            return \"Context information is below.---------------------{contex}---------------------Given the context information and not prior knowledge, answer the query with a bulleted song playlist and a small description of the playlist at the end.Query: {query_str}Answer: \"\n        elif is_recommendation:\n            return \"Context information is below.---------------------{contex}---------------------Given the context information and not prior knowledge, answer the query with a single song recommendation and a short explanation.Query: {query_str}Answer: \"\n        else:\n            return \"Context information is below.---------------------{contex}---------------------Given the context information and not prior knowledge, answer the query.Query: {query_str}Answer: \"\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"query":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"query","display_name":"User Query","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Sorts keywords into genre, event, single recommendation, or generic query categories.","base_classes":["object","str","Text"],"display_name":"Query Parser","documentation":"","custom_fields":{"query":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"edited":true},"id":"CustomComponent-Tddks","description":"Sorts keywords into genre, event, single recommendation, or generic query categories.","display_name":"Query Parser"},"selected":false,"width":384,"height":325,"dragging":false,"positionAbsolute":{"x":-1651.2504296184306,"y":5513.0145249745065}},{"id":"Prompt-DjYpT","type":"genericNode","position":{"x":-512.7013227979803,"y":5348.624645645489},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.field_typing import TemplateField\nfrom langflow.field_typing.prompt import Prompt\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Empty Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    async def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Prompt:\n        prompt = await Prompt.from_template_and_variables(template, kwargs)  # type: ignore\n        self.status = prompt.format_text()\n        return prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","contex":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"contex","display_name":"contex","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"query_str":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"query_str","display_name":"query_str","advanced":false,"input_types":["Document","Message","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Prompt","Record"],"name":"Empty Prompt","display_name":"Empty Prompt","documentation":"","custom_fields":{"template":["contex","query_str"]},"output_types":["Prompt"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-DjYpT","description":"Create a prompt template with dynamic variables.","display_name":"Empty Prompt"},"selected":false,"width":384,"height":513,"positionAbsolute":{"x":-512.7013227979803,"y":5348.624645645489},"dragging":false},{"id":"OpenAIModel-g9Yyf","type":"genericNode","position":{"x":63.96891062463408,"y":5546.127947348422},"data":{"type":"OpenAIModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"input_types":["Text","Record","Prompt"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import NestedDict, Text\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n\n    field_order = [\n        \"max_tokens\",\n        \"model_kwargs\",\n        \"model_name\",\n        \"openai_api_base\",\n        \"openai_api_key\",\n        \"temperature\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_value\": {\"display_name\": \"Input\", \"input_types\": [\"Text\", \"Record\", \"Prompt\"]},\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"advanced\": False,\n                \"options\": MODEL_NAMES,\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": True,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"info\": \"The OpenAI API Key to use for the OpenAI model.\",\n                \"advanced\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"value\": 0.1,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        openai_api_key: str,\n        temperature: float = 0.1,\n        model_name: str = \"gpt-3.5-turbo\",\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature,\n        )\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":256,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-4o","fileTypes":[],"file_path":"","password":false,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","load_from_db":true,"title_case":false,"input_types":["Text"],"value":"OPENAI_KEY"},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.1,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["object","str","Text"],"display_name":"OpenAI","documentation":"","custom_fields":{"input_value":null,"openai_api_key":null,"temperature":null,"model_name":null,"max_tokens":null,"model_kwargs":null,"openai_api_base":null,"stream":null,"system_message":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["max_tokens","model_kwargs","model_name","openai_api_base","openai_api_key","temperature","input_value","system_message","stream"],"beta":false,"name":"OpenAI"},"id":"OpenAIModel-g9Yyf"},"selected":false,"width":384,"height":571,"positionAbsolute":{"x":63.96891062463408,"y":5546.127947348422},"dragging":false},{"id":"CustomComponent-hNKfF","type":"genericNode","position":{"x":-2363.066069923316,"y":5146.962307958314},"data":{"type":"CustomComponent","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\n\n\nclass Component(CustomComponent):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n\n    def build_config(self):\n        return {\"param\": {\"display_name\": \"Parameter\"}}\n\n    def build(self, param: str) -> Record:\n        return Record(data=param)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"param":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"param","display_name":"Parameter","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Use as a template to create your own component.","icon":"custom_components","base_classes":["Record"],"display_name":"Custom Component","documentation":"http://docs.langflow.org/components/custom","custom_fields":{"param":null},"output_types":["Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"name":"Custom Component"},"id":"CustomComponent-hNKfF"},"selected":false,"width":384,"height":325,"positionAbsolute":{"x":-2363.066069923316,"y":5146.962307958314},"dragging":false}],"edges":[{"source":"OpenAIEmbeddings-JTBUM","sourceHandle":"{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-JTBUMœ}","target":"AstraDBSearch-yJfFU","targetHandle":"{œfieldNameœ:œembeddingœ,œidœ:œAstraDBSearch-yJfFUœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","data":{"targetHandle":{"fieldName":"embedding","id":"AstraDBSearch-yJfFU","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OpenAIEmbeddings","id":"OpenAIEmbeddings-JTBUM"}},"style":{"stroke":"#555"},"className":"","id":"reactflow__edge-OpenAIEmbeddings-JTBUM{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-JTBUMœ}-AstraDBSearch-yJfFU{œfieldNameœ:œembeddingœ,œidœ:œAstraDBSearch-yJfFUœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}"},{"source":"OpenAIEmbeddings-3lzO1","sourceHandle":"{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-3lzO1œ}","target":"AstraDB-b9hPF","targetHandle":"{œfieldNameœ:œembeddingœ,œidœ:œAstraDB-b9hPFœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}","data":{"targetHandle":{"fieldName":"embedding","id":"AstraDB-b9hPF","inputTypes":null,"type":"Embeddings"},"sourceHandle":{"baseClasses":["Embeddings"],"dataType":"OpenAIEmbeddings","id":"OpenAIEmbeddings-3lzO1"}},"style":{"stroke":"#555"},"className":"","id":"reactflow__edge-OpenAIEmbeddings-3lzO1{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-3lzO1œ}-AstraDB-b9hPF{œfieldNameœ:œembeddingœ,œidœ:œAstraDB-b9hPFœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}"},{"source":"Prompt-Ev0wU","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-Ev0wUœ}","target":"OpenAIModel-IfDFk","targetHandle":"{œfieldNameœ:œinput_valuesœ,œidœ:œOpenAIModel-IfDFkœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_values","id":"OpenAIModel-IfDFk","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"Prompt","id":"Prompt-Ev0wU"}},"style":{"stroke":"#555"},"className":"","id":"reactflow__edge-Prompt-Ev0wU{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-Ev0wUœ}-OpenAIModel-IfDFk{œfieldNameœ:œinput_valuesœ,œidœ:œOpenAIModel-IfDFkœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"AstraDBSearch-yJfFU","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œAstraDBSearchœ,œidœ:œAstraDBSearch-yJfFUœ}","target":"RecordsToText-5RagF","targetHandle":"{œfieldNameœ:œrecordsœ,œidœ:œRecordsToText-5RagFœ,œinputTypesœ:null,œtypeœ:œRecordœ}","data":{"targetHandle":{"fieldName":"records","id":"RecordsToText-5RagF","inputTypes":null,"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"AstraDBSearch","id":"AstraDBSearch-yJfFU"}},"style":{"stroke":"#555"},"className":"","id":"reactflow__edge-AstraDBSearch-yJfFU{œbaseClassesœ:[œRecordœ],œdataTypeœ:œAstraDBSearchœ,œidœ:œAstraDBSearch-yJfFUœ}-RecordsToText-5RagF{œfieldNameœ:œrecordsœ,œidœ:œRecordsToText-5RagFœ,œinputTypesœ:null,œtypeœ:œRecordœ}"},{"source":"ChatInput-TfPvB","sourceHandle":"{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-TfPvBœ}","target":"CustomComponent-Tddks","targetHandle":"{œfieldNameœ:œqueryœ,œidœ:œCustomComponent-Tddksœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"query","id":"CustomComponent-Tddks","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-TfPvB"}},"id":"reactflow__edge-ChatInput-TfPvB{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-TfPvBœ}-CustomComponent-Tddks{œfieldNameœ:œqueryœ,œidœ:œCustomComponent-Tddksœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","className":""},{"source":"CustomComponent-Tddks","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Tddksœ}","target":"Prompt-DjYpT","targetHandle":"{œfieldNameœ:œtemplateœ,œidœ:œPrompt-DjYpTœ,œinputTypesœ:[œTextœ],œtypeœ:œpromptœ}","data":{"targetHandle":{"fieldName":"template","id":"Prompt-DjYpT","inputTypes":["Text"],"type":"prompt"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"CustomComponent","id":"CustomComponent-Tddks"}},"id":"reactflow__edge-CustomComponent-Tddks{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Tddksœ}-Prompt-DjYpT{œfieldNameœ:œtemplateœ,œidœ:œPrompt-DjYpTœ,œinputTypesœ:[œTextœ],œtypeœ:œpromptœ}","className":""},{"source":"ChatInput-TfPvB","sourceHandle":"{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-TfPvBœ}","target":"AstraDBSearch-yJfFU","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œAstraDBSearch-yJfFUœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"AstraDBSearch-yJfFU","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-TfPvB"}},"id":"reactflow__edge-ChatInput-TfPvB{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-TfPvBœ}-AstraDBSearch-yJfFU{œfieldNameœ:œinput_valueœ,œidœ:œAstraDBSearch-yJfFUœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","className":""},{"source":"RecordsToText-5RagF","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œRecordsToTextœ,œidœ:œRecordsToText-5RagFœ}","target":"Prompt-DjYpT","targetHandle":"{œfieldNameœ:œcontexœ,œidœ:œPrompt-DjYpTœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"contex","id":"Prompt-DjYpT","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"RecordsToText","id":"RecordsToText-5RagF"}},"id":"reactflow__edge-RecordsToText-5RagF{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œRecordsToTextœ,œidœ:œRecordsToText-5RagFœ}-Prompt-DjYpT{œfieldNameœ:œcontexœ,œidœ:œPrompt-DjYpTœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"ChatInput-TfPvB","sourceHandle":"{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-TfPvBœ}","target":"Prompt-DjYpT","targetHandle":"{œfieldNameœ:œquery_strœ,œidœ:œPrompt-DjYpTœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"query_str","id":"Prompt-DjYpT","inputTypes":["Document","Message","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["Message","object","str","Text"],"dataType":"ChatInput","id":"ChatInput-TfPvB"}},"id":"reactflow__edge-ChatInput-TfPvB{œbaseClassesœ:[œMessageœ,œobjectœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-TfPvBœ}-Prompt-DjYpT{œfieldNameœ:œquery_strœ,œidœ:œPrompt-DjYpTœ,œinputTypesœ:[œDocumentœ,œMessageœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-DjYpT","sourceHandle":"{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-DjYpTœ}","target":"OpenAIModel-g9Yyf","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-g9Yyfœ,œinputTypesœ:[œTextœ,œRecordœ,œPromptœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-g9Yyf","inputTypes":["Text","Record","Prompt"],"type":"str"},"sourceHandle":{"baseClasses":["Prompt","Record"],"dataType":"Prompt","id":"Prompt-DjYpT"}},"id":"reactflow__edge-Prompt-DjYpT{œbaseClassesœ:[œPromptœ,œRecordœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-DjYpTœ}-OpenAIModel-g9Yyf{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-g9Yyfœ,œinputTypesœ:[œTextœ,œRecordœ,œPromptœ],œtypeœ:œstrœ}","className":""},{"source":"OpenAIModel-g9Yyf","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-g9Yyfœ}","target":"ChatOutput-xZCSP","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-xZCSPœ,œinputTypesœ:[œTextœ,œRecordœ,œMessageœ],œtypeœ:œUnion[str, Message, Record]œ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-xZCSP","inputTypes":["Text","Record","Message"],"type":"Union[str, Message, Record]"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"OpenAIModel","id":"OpenAIModel-g9Yyf"}},"id":"reactflow__edge-OpenAIModel-g9Yyf{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-g9Yyfœ}-ChatOutput-xZCSP{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-xZCSPœ,œinputTypesœ:[œTextœ,œRecordœ,œMessageœ],œtypeœ:œUnion[str, Message, Record]œ}","className":""},{"source":"CustomComponent-hp3I4","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-hp3I4œ}","target":"Prompt-Ev0wU","targetHandle":"{œfieldNameœ:œinputsœ,œidœ:œPrompt-Ev0wUœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"inputs","id":"Prompt-Ev0wU","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"CustomComponent","id":"CustomComponent-hp3I4"}},"id":"reactflow__edge-CustomComponent-hp3I4{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-hp3I4œ}-Prompt-Ev0wU{œfieldNameœ:œinputsœ,œidœ:œPrompt-Ev0wUœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","className":""},{"source":"OpenAIModel-IfDFk","sourceHandle":"{œbaseClassesœ:[œRecordœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-IfDFkœ}","target":"AstraDB-b9hPF","targetHandle":"{œfieldNameœ:œinputsœ,œidœ:œAstraDB-b9hPFœ,œinputTypesœ:null,œtypeœ:œRecordœ}","data":{"targetHandle":{"fieldName":"inputs","id":"AstraDB-b9hPF","inputTypes":null,"type":"Record"},"sourceHandle":{"baseClasses":["Record"],"dataType":"OpenAIModel","id":"OpenAIModel-IfDFk"}},"id":"reactflow__edge-OpenAIModel-IfDFk{œbaseClassesœ:[œRecordœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-IfDFkœ}-AstraDB-b9hPF{œfieldNameœ:œinputsœ,œidœ:œAstraDB-b9hPFœ,œinputTypesœ:null,œtypeœ:œRecordœ}","className":""}],"viewport":{"x":954.9434825789158,"y":-1392.1641342325818,"zoom":0.29919384970077145}},"description":"","name":"Spotify Recommender 2.0","last_tested_version":"0.0.14","is_component":false}